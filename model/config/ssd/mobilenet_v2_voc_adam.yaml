# Network
#   Task: 아래 목록중 1가지 혹은 복수 선택 가능
#         네트워크마다 지원하는 Task가 다르므로, 굳이 건드리지 않아도 됨
#         'Classification'          : 분류 (Class)
#         'Object Detection'        : 객체 검출 (BBox)
#         'Instance Segmentation'   : 객체 검출 + 영역 분할 (BBox + Mask)
#         'Semantic Segmentation'   : 영역 분할 (Mask)
#         'Keypoint Detection'      : 특징점 추출 (Keypoint)
# Method: 아래 목록중 1가지 선택
#         'ssd'                     : Single Shot Detector
#         'yolo'                    : You Only Look Once
# Type: 네트워크의 Backbone이나 목적에 따른 분류를 말함. 아래 목록중 1가지 선택
#   SSD의 경우
#         'vgg16'                   : VGG16 SSD
#         'mobilenet_v1'            : MobileNet V1 SSD
#         'mobilenet_v2'            : MobileNet V2 SSD
#         'mobilenet_v3'            : MobileNet V3 SSD
# YOLO1의 경우
#         'Tiny'                   : YOLO1 Tiny
#         'Full'                   : YOLO1 Full
# Loss: Wandb에서 Loss를 표시할 때 사용하는 이름. 네트워크마다 정해져있는 Loss가 다르므로, 굳이 건드리지 않아도 됨
#   SSD의 경우: ['Total', 'Class', 'Regression']
#   YOLO1의 경우: ['Total', 'XY', 'WH', 'Confidence', 'Class']
# Metric: 성능평가에 사용할 Metric 지정. Task에 따라 적절한 Metric 설정
#   Classification: ['Accuracy', 'F1', 'Precision', 'Recall']
#   Object Detection: ['mAP']
# MAP_MODE: mAP 계산에 사용할 계산 방식을 설정
#   MAP_MODE: ['11point', '101point', 'all']
# Backbone Weight: Backbone의 Weight를 지정
#   None: Weight를 사용하지 않음
#   'torchvision': torchvision에서 제공하는 Weight 사용
#   'weight_path': weight_path에 지정된 경로의 Weight 사용 (우리가 Pretrained 한 경우)
# Pretrained Weight: Pretrained Weight를 지정 (주로 이전에 학습한 네트워크를 이어서 학습할 때 사용)
#   None: Weight를 사용하지 않음
#   'weight_path': weight_path에 지정된 경로의 Weight 사용
# Input Size: 네트워크의 Input Size를 지정
#   [height, width]
TASK: ['Object Detection']
METHOD: 'ssd'
TYPE: 'mobilenet_v2' # {'mobilenetv2'}
METRIC: ['mAP']
MAP_MODE: '101point'
LOSS: ['Total', 'Class', 'Regression']
BACKBONE_WEIGHT: 'torchvision' # {None, 'torchvision'}
PRETRAINED_WEIGHT: None # weight_path
INPUT_SIZE: [300, 300] # (height, width)

# System
#   WORKERS: DataLoader에서 사용할 Worker의 수
WORKERS: 2 # workers per gpu

# HyperParameter
# 하이퍼 파라미터의 경우 네트워크마다 다르기 때문에, 관련 스크립트를 참조하여 작성
### Network
# MEAN: 네트워크의 Input에 사용할 Mean
# STD: 네트워크의 Input에 사용할 Standard Deviation
# x = (x - MEAN) / STD
MEAN: [0.485, 0.456, 0.406]
STD: [0.229, 0.224, 0.225]

### NMS
#   Non-Maximum Suppression 후처리를 위한 하이퍼 파라미터
#   TOPK: NMS에서 사용할 BBox의 최대 개수
#   NMS_IOU_THRESHOLD: NMS에서 사용할 IOU Threshold
TOPK: 200
NMS_IOU_THRESHOLD: 0.5

### Training
#   학습 전략의 경우 네트워크마다 다르기 때문에, 관련 스크립트를 참조하여 작성
#     STEPLR: 학습률을 변경할 Epoch를 지정 (주로 StepLR Decay를 사용할 때 사용)
#     LR: 학습률
#     BATCH_SIZE_MULTI_GPU: 배치 사이즈. 만약 32로 설정하고, 2GPU 사용시, 각 GPU마다 16개씩 배치 할당됨
#     WEIGHT_DECAY: L2 Regularization의 Weight Decay
#     MOMENTUM: Momentum Optimizer의 Momentum (주로 SGD를 사용할 때 사용)
STEPLR: [360000, 430000, 500000]
LR: 0.004
BATCH_SIZE_MULTI_GPU: 8 
WEIGHT_DECAY: 0.0005
MOMENTUM: 0.9

### loss
#   LOSS_ALPHA: SSD의 경우 Loss가 ['Total', 'Class', 'Regression']로 구성되는데, 
#               Total Loss = Class Loss + Regression Loss * LOSS_ALPHA와 같이 Loss간 가중치를 조절에 사용됨
LOSS_ALPHA: 1.0

### Anchor
#   ANCHOR_N: Anchor의 개수
#   ANCHOR_SCALE: Anchor의 Scale
#   ANCHOR_GRID_W: Anchor와 관련된 Feature Map의 Width
#   ANCHOR_GRID_H: Anchor와 관련된 Feature Map의 Height
ANCHOR_N: [4, 6, 6, 6, 4, 4]
# ANCHOR_SCALE: [0.1, 0.2, 0.375, 0.55, 0.725, 0.9]
ANCHOR_SCALE: [0.1, 0.35, 0.5, 0.65, 0.8, 0.95]
ANCHOR_GRID_W: [19, 10, 5, 3, 2, 1]
ANCHOR_GRID_H: [19, 10, 5, 3, 2, 1]

### Augmentation
# 네트워크 학습에 사용할 Augmentation을 설정
#     HSV_PROB: HSV Augmentation을 사용할 확률
#     HSV_HGAIN: HSV Augmentation에서 Hue에 사용할 Gain
#     HSV_SGAIN: HSV Augmentation에서 Saturation에 사용할 Gain
#     HSV_VGAIN: HSV Augmentation에서 Value에 사용할 Gain
HSV_PROB: 1.0
HSV_HGAIN: 0.015
HSV_SGAIN: 0.7
HSV_VGAIN: 0.4

# (Mosaic의 경우 현재 수정 필요)
#     MOSAIC_PROB: Mosaic Augmentation을 사용할 확률 
#     MOSAIC_CANVAS_RANGE: Mosaic Augmentation에서 Canvas의 크기를 결정할 때 사용할 Range
MOSAIC_PROB: 0.0 # not use
MOSAIC_CANVAS_RANGE: 1.0

# Perspective transform
#   Object Detection의 경우, 각 객체별 Mask가 있어야 좋은 성능이 나옴.
#   그외 Task의 경우 그냥 사용해도 무방함
#     PERSPECTIVE_PROB: Perspective Augmentation을 사용할 확률
#     PERSPECTIVE_DEGREE: Perspective Augmentation에서 회전변환에 사용할 값 
#     PERSPECTIVE_TRANSLATE: Perspective Augmentation에서 이동변환에 사용할 값
#     PERSPECTIVE_SCALE: Perspective Augmentation에서 크기변환에 사용할 값
#     PERSPECTIVE_SHEAR: Perspective Augmentation에서 기울이는 변환에 사용할 값
#     PERSPECTIVE_PERSPECTIVE: Perspective Augmentation에서 투영변환에 사용할 값
PERSPECTIVE_PROB: 0.0 # not use
PERSPECTIVE_DEGREE: 10.0
PERSPECTIVE_TRANSLATE: 0.1
PERSPECTIVE_SCALE: 0.1
PERSPECTIVE_SHEAR: 5.0
PERSPECTIVE_PERSPECTIVE: 0.0

#     RANDOM_ZOOMOUT_PROB: Random Zoomout Augmentation을 사용할 확률
#     RANDOM_ZOOMOUT_MAX_SCALE: Random Zoomout Augmentation에서 사용할 최대 Scale. 4.0으로 설정하면 최대 1/4크기로 Zoomout
RANDOM_ZOOMOUT_PROB: 0.5
RANDOM_ZOOMOUT_MAX_SCALE: 4.0

#     RANDOM_CROP_PROB: Random Crop Augmentation을 사용할 확률
#     RANDOM_CROP_MIN_OVERLAP: Random Crop Augmentation에서 사용할 최소 Overlap
#                              0.3으로 설정하면, 0.3 이상의 Overlap을 가지는 BBox가 존재해야 Crop
RANDOM_CROP_PROB: 1.0
RANDOM_CROP_MIN_OVERLAP: 0.3