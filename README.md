<p align="center"><img src="./images/M-FastLogo.png" width="700px" height="200px" title="M-Fast Logo"/></p>

# M-fast ğŸƒâ€â™‚ï¸ğŸƒğŸƒâ€â™€ï¸
Mono AI 

## :small_blue_diamond: TODO 
- One-node, Multi-GPU ì§€ì›
- Multi-node, Multi-GPU ì§€ì›
- Targetì— ë”°ë¥¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì§€ì›(acacia, belladonna, etc.)
- Pretrained ì—¬ë¶€ì— ë”°ë¥¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì§€ì›(Pretrained, Not Pretrained, MOCO)
- Dataset Mergeì— ë”°ë¥¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì§€ì›(COCO+VOC)
    * utils/load_configì—ì„œ í˜„ì¬ ë‹¨ì¼ ë°ì´í„°ì…‹ë§Œ ì§€ì›
- ë‹¤ë¥¸ Datasetì— ëŒ€í•œ í‰ê°€ íŒŒì´í”„ë¼ì¸ ì§€ì›(COCO, VOC, CrowdHuman, Argoseye)

## :one: ì‚¬ìš©ë²•

### :small_blue_diamond: Nvidia-docker ì„¤ì¹˜
```bash
TODO
```

### :small_blue_diamond: Dockerfileì„ ì´ìš©í•œ ì‹¤í–‰
```bash
docker build --tag mfast .

docker run -it --rm mfast \
--runtime=nvidia -e NVIDIA_VISIBLE_DEVICES=0 \
-v {M-fast ê²½ë¡œ}:/M-fast \
-v {ë°ì´í„°ì…‹ ê²½ë¡œ}:/dataset \ 
-shm-size=8G
```

ì˜ˆì‹œ
```
docker run -it --rm --gpus=all -v C:\M-fast:/M-fast -v C:\dataset:/dataset --shm-size=8g mfast
```

### Docker ë‚´ë¶€ì—ì„œ ì‹¤í–‰
#### Single Node Single GPU 
  - COCO 
```bash
python train_model_single.py --config {config ê²½ë¡œ} --coco 
```
  - VOC
```bash
python train_model_single.py --config {config ê²½ë¡œ} --voc
```
  - CrowdHuman
```bash
python train_model_single.py --config {config ê²½ë¡œ} --crowdhuman
```
  - Argoseye
```bash
python train_model_single.py --config {config ê²½ë¡œ} --argoseye
```

#### Single Node Multi GPU
  - COCO 
```bash
python train_model.py --config {config ê²½ë¡œ} --coco
```
  - VOC
```bash
python train_model.py --config {config ê²½ë¡œ} --voc
```
  - CrowdHuman
```bash
python train_model.py --config {config ê²½ë¡œ} --crowdhuman
```
  - Argoseye
```bash
python train_model.py --config {config ê²½ë¡œ} --argoseye
```

## :two: Backbone
### ì§€ì›í•˜ëŠ” ëª¨ë¸
- [ ] Vgg16
- [ ] MobileNet-V1
- [ ] MobileNet-V2
- [ ] MobileNet-V3

### ì§€ì›í•˜ëŠ” Dataset
- [ ] ImageNet
- [ ] OpenImagesV7
- [ ] PASS

### ì„±ëŠ¥
#### :radio_button: ImageNet Dataset
|Backbone|Method|Dataset|Top-1|Top-5|
|:---:|:---:|:---:|:---:|:---:|
|Vgg16|Classification|ImageNet|-|-|
|MobileNet-V1|Classification|ImageNet|-|-|
|MobileNet-V2|Classification|ImageNet|-|-|
|MobileNet-V3|Classification|ImageNet|-|-|

#### :radio_button: OpenImagesV7 Dataset
|Backbone|Method|Dataset|Top-1|Top-5|
|:---:|:---:|:---:|:---:|:---:|
|Vgg16|MOCO|OpenImagesV7|-|-|
|MobileNet-V1|MOCO|OpenImagesV7|-|-|
|MobileNet-V2|MOCO|OpenImagesV7|-|-|
|MobileNet-V3|MOCO|OpenImagesV7|-|-|

#### :radio_button: PASS Dataset
|Backbone|Method|Dataset|Top-1|Top-5|
|:---:|:---:|:---:|:---:|:---:|
|Vgg16|MOCO|PASS|-|-|
|MobileNet-V1|MOCO|PASS|-|-|
|MobileNet-V2|MOCO|PASS|-|-|
|MobileNet-V3|MOCO|PASS|-|-|
  
## :three: Model
### ì§€ì›í•˜ëŠ” ëª¨ë¸
#### 2016
- [ ] YoloV1 (You Only Look Once, CVPR 2016)
- [ ] SSD (Single Shot MultiBox Detector, ECCV 2016)
  - vgg16, mobilenet-v1, mobilenet-v2, mobilenet-v3
- [ ] YOLO9000 (YOLO9000: Better, Faster, Stronger, CVPR 2017)

#### 2019
- [ ] CenterNet (Objects as Points, CVPR 2019)


### ì§€ì›í•˜ëŠ” Dataset
- [ ] VOC2007+2012 (PASCAL VOC, 20 classes)
- [ ] COCO2017 (Common Objects in Context, 80 classes)
- [ ] Crowd Human (Crowd Human, 2 class)
- [ ] Argoseye (Argoseye, 1 class)

### ì„±ëŠ¥
* ì¼ë°˜ì ìœ¼ë¡œ AP<sup>small</sup>ì˜ ê²½ìš° 32x32 ì´í•˜ì˜ ì‘ì€ ê°ì²´ë¥¼, AP<sup>medium</sup>ì˜ ê²½ìš° 96x96 ì´í•˜ì˜ ì¤‘ê°„ ê°ì²´ë¥¼, AP<sup>large</sup>ì˜ ê²½ìš° 96x96 ì´ìƒì˜ í° ê°ì²´ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
* ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°ì— ë”°ë¼ ê° ìš”ì†Œë“¤ì´ ë‹¤ë¥´ê²Œ ë™ì‘í•˜ë¯€ë¡œ, ì—¬ê¸°ì—ì„œëŠ” AP<sup>small</sup>ì˜ ê²½ìš° ê°ì²´ì˜ bounding boxì˜ ë„“ì´ê°€ (1/6)<sup>2</sup> ì´í•˜ì¸ ê²½ìš°ë¥¼, AP<sup>medium</sup>ì˜ ê²½ìš° ê°ì²´ì˜ bounding boxì˜ ë„“ì´ê°€ (1/6)<sup>2</sup> ì´ìƒ (1/3)<sup>2</sup> ì´í•˜ì¸ ê²½ìš°ë¥¼, AP<sup>large</sup>ì˜ ê²½ìš° ê°ì²´ì˜ bounding boxì˜ ë„“ì´ê°€ (1/3)<sup>2</sup> ì´ìƒì¸ ê²½ìš°ë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.
* ê·¸ë¦¬ê³  AP<sup>small</sup>ì˜ ê²½ìš° 0.5 IoU thresholdê°€, AP<sup>medium</sup>ì˜ ê²½ìš° 0.6 IoU thresholdê°€, AP<sup>large</sup>ì˜ ê²½ìš° 0.7 IoU thresholdê°€ ì ìš©ë©ë‹ˆë‹¤.

#### :radio_button: COCO2017 Dataset
|Model|Size|pretrained|AP0.5:0.95|AP50|AP75|AP<sup>small</sup>|AP<sup>midium</sup>|AP<sup>large</sup>|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|YoloV1|-|-|-|-|-|-|-|-|
|SSD|-|-|-|-|-|-|-|-|

#### :radio_button: VOC2007+2012 Dataset
|Model|Size|pretrained|AP0.5:0.95|AP50|AP75|AP<sup>small</sup>|AP<sup>midium</sup>|AP<sup>large</sup>|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|YoloV1|-|-|-|-|-|-|-|-|
|SSD|-|-|-|-|-|-|-|-|

#### :radio_button: CrowdHuman Dataset
|Model|Size|pretrained|AP0.5:0.95|AP50|AP75|AP<sup>small</sup>|AP<sup>midium</sup>|AP<sup>large</sup>|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|YoloV1|-|-|-|-|-|-|-|-|
|SSD|-|-|-|-|-|-|-|-|

#### :radio_button: Argoseye Dataset
|Model|Size|pretrained|AP0.5:0.95|AP50|AP75|AP<sup>small</sup>|AP<sup>midium</sup>|AP<sup>large</sup>|
|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|:---:|
|YoloV1|-|-|-|-|-|-|-|-|
|SSD|-|-|-|-|-|-|-|-|